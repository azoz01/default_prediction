stages:
  split_data:
    cmd: python pipelines/bin/split_data.py
    deps:
    - ${paths.data.raw}
    - pipelines/bin/split_data.py
    - utils
    params:
    - split_data.valid_size
    - split_data.test_size
    - split_data.random_state
    outs:
    - ${paths.data.splitted}
  clean:
    cmd: python pipelines/bin/clean_data.py
    deps:
    - ${paths.data.splitted}
    - pipelines/bin/clean_data.py
    - utils
    outs:
    - ${paths.data.clean}
    - ${paths.pipelines.serialized}/data_cleaner.pkl
  transform_numerical_columns:
    cmd: python pipelines/bin/transform_numerical_columns.py
    deps:
    - ${paths.data.clean}
    - pipelines/bin/transform_numerical_columns.py
    - utils
    outs:
    - ${paths.data.transformed_numerical_columns}
    - ${paths.pipelines.serialized}/numerical_columns_transformer.pkl
  balance_data:
    cmd: python pipelines/bin/balance_data.py
    deps:
    - ${paths.data.transformed_numerical_columns}
    - pipelines/bin/balance_data.py
    - pipelines/lib/data_balance
    - utils
    params:
    - balance_data.method
    outs:
    - ${paths.data.balanced}
  transform_categorical_columns:
    cmd: python pipelines/bin/transform_categorical_columns.py
    deps:
    - ${paths.data.balanced}
    - pipelines/bin/transform_categorical_columns.py
    - utils
    params:
    - category_embedding
    - transform_categorical_columns.method
    outs:
    - ${paths.data.transformed_categorical_columns}
    - ${paths.pipelines.serialized}/categorical_columns_transformer.pkl
  reduce_data:
    cmd: python pipelines/bin/reduce_data.py
    deps:
    - pipelines/bin/reduce_data.py
    - ${paths.data.transformed_categorical_columns}
    - utils
    params:
    - frufs
    - rfe
    - reduce_data.method
    outs:
    - ${paths.data.reduced}
    - ${paths.pipelines.serialized}/data_reductor.pkl
# TODO: add model_train stage
# TODO: add model calibration stage
# TODO: add fetching from google drive
