{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_parquet(\"resources/data/splitted/X_train.parquet\")\n",
    "y = pd.read_parquet(\"resources/data/splitted/y_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_title                      0.054343\n",
       "emp_length                     0.038570\n",
       "mths_since_last_delinq         0.557768\n",
       "mths_since_last_record         0.875112\n",
       "revol_util                     0.000847\n",
       "last_pymnt_d                   0.002140\n",
       "last_credit_pull_d             0.000090\n",
       "collections_12_mths_ex_med     0.000232\n",
       "mths_since_last_major_derog    0.812575\n",
       "tot_coll_amt                   0.251515\n",
       "tot_cur_bal                    0.251515\n",
       "total_rev_hi_lim               0.251515\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_columns_mask = X.isna().any(axis=0)\n",
    "X.loc[:, missing_columns_mask].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Charged Off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_status\n",
       "7  Charged Off"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.loc[X[\"last_pymnt_d\"].isna()].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data in `last_pymnt_d` is possibly due to not paying first installment. Let's set it to oldest date present in dataset and add additional column `first_inst`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column = \"last_pymnt_d\"\n",
    "X[\"first_inst\"] = ~X[column].isna()\n",
    "splitted_col = X.loc[~X[column].isna().values, column].str.split(\"-\", expand=True)\n",
    "min_yr = splitted_col[1].min()\n",
    "min_mon = \"Jan\"\n",
    "min_date = f\"{min_mon}-{min_yr}\"\n",
    "min_date\n",
    "X[column] = X[column].fillna(min_date)\n",
    "X[column].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogous to previous column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column = \"last_credit_pull_d\"\n",
    "X[\"no_credit_pull\"] = ~X[column].isna()\n",
    "splitted_col = X.loc[~X[column].isna().values, column].str.split(\"-\", expand=True)\n",
    "min_yr = splitted_col[1].min()\n",
    "min_mon = \"Jan\"\n",
    "min_date = f\"{min_mon}-{min_yr}\"\n",
    "min_date\n",
    "X[column] = X[column].fillna(min_date)\n",
    "X[column].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in constants.COLUMNS_TO_IMPUTE_MISSING_CATEGORY:\n",
    "    X[column] = X[column].fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in constants.COLUMNS_TO_IMPUTE_0:\n",
    "    X[column] = X[column].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"mths_since_last_delinq\"] = pd.qcut(\n",
    "    X[\"mths_since_last_delinq\"],\n",
    "    [0, 0.25, 0.5, 0.75, 1],\n",
    "    labels=[\"1_quant\", \"2_quant\", \"3_quant\", \"4_quant\"],\n",
    ")\n",
    "X[\"mths_since_last_delinq\"] = X[\"mths_since_last_delinq\"].cat.add_categories(\n",
    "    [\"no_delinq\"]\n",
    ")\n",
    "X[\"mths_since_last_delinq\"] = X[\"mths_since_last_delinq\"].fillna(\"no_delinq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"mths_since_last_record\"] = pd.qcut(\n",
    "    X[\"mths_since_last_record\"],\n",
    "    [0, 0.25, 0.5, 0.75, 1],\n",
    "    labels=[\"1_quant\", \"2_quant\", \"3_quant\", \"4_quant\"],\n",
    ")\n",
    "X[\"mths_since_last_record\"] = X[\"mths_since_last_record\"].cat.add_categories(\n",
    "    [\"no_record\"]\n",
    ")\n",
    "X[\"mths_since_last_record\"] = X[\"mths_since_last_record\"].fillna(\"no_record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"mths_since_last_major_derog\"] = pd.qcut(\n",
    "    X[\"mths_since_last_major_derog\"],\n",
    "    [0, 0.25, 0.5, 0.75, 1],\n",
    "    labels=[\"1_quant\", \"2_quant\", \"3_quant\", \"4_quant\"],\n",
    ")\n",
    "X[\"mths_since_last_major_derog\"] = X[\"mths_since_last_major_derog\"].cat.add_categories(\n",
    "    [\"no_major_derog\"]\n",
    ")\n",
    "X[\"mths_since_last_major_derog\"] = X[\"mths_since_last_major_derog\"].fillna(\n",
    "    \"no_major_derog\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"revol_util\"] = X[\"revol_util\"].fillna(X[\"revol_util\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "revol_util    54.288903\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[[\"revol_util\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rev_hi_lim    0.251515\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_columns_mask = X.isna().any(axis=0)\n",
    "X.loc[:, missing_columns_mask].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = X.select_dtypes(\"object\").columns\n",
    "X[object_columns] = X[object_columns].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antoni/.miniconda3/envs/default_prediction/lib/python3.10/site-packages/miceforest/ImputationKernel.py:369: UserWarning: [emp_title,home_ownership,issue_d,purpose,earliest_cr_line,last_pymnt_d,last_credit_pull_d,application_type] have very rare categories, it is a good idea to group these, or set the min_data_in_leaf parameter to preventlightgbm from outputting 0.0 probabilities.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized logger with name mice 1-2\n",
      "Dataset 0\n",
      "1  | total_rev_hi_lim\n",
      "2  | total_rev_hi_lim\n",
      "Dataset 1\n",
      "1  | total_rev_hi_lim\n",
      "2  | total_rev_hi_lim\n",
      "Dataset 2\n",
      "1  | total_rev_hi_lim\n",
      "2  | total_rev_hi_lim\n",
      "Dataset 3\n",
      "1  | total_rev_hi_lim\n",
      "2  | total_rev_hi_lim\n",
      "Dataset 4\n",
      "1  | total_rev_hi_lim\n",
      "2  | total_rev_hi_lim\n"
     ]
    }
   ],
   "source": [
    "import miceforest as mf\n",
    "\n",
    "kernel = mf.ImputationKernel(data=X, datasets=5, random_state=42)\n",
    "kernel.mice(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.transform(X).isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = X.loc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No missing values to impute.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/antoni/sync/others/default_prediction/notebooks/preprocessing_poc/handling_missing_data.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/antoni/sync/others/default_prediction/notebooks/preprocessing_poc/handling_missing_data.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m kernel\u001b[39m.\u001b[39;49mtransform(sample)\n",
      "File \u001b[0;32m~/.miniconda3/envs/default_prediction/lib/python3.10/site-packages/miceforest/ImputationKernel.py:1213\u001b[0m, in \u001b[0;36mImputationKernel.transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1208\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m \u001b[39m    Method for calling a kernel when used in a sklearn pipeline.\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m \u001b[39m    Should not be called by the user directly.\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1213\u001b[0m     new_dat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimpute_new_data(X, datasets\u001b[39m=\u001b[39;49m[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m   1214\u001b[0m     \u001b[39mreturn\u001b[39;00m new_dat\u001b[39m.\u001b[39mcomplete_data(dataset\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.miniconda3/envs/default_prediction/lib/python3.10/site-packages/miceforest/ImputationKernel.py:1602\u001b[0m, in \u001b[0;36mImputationKernel.impute_new_data\u001b[0;34m(self, new_data, datasets, iterations, save_all_iterations, copy_data, random_state, random_seed_array, verbose)\u001b[0m\n\u001b[1;32m   1599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_models \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1600\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo models were saved.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1602\u001b[0m imputed_data \u001b[39m=\u001b[39m ImputedData(\n\u001b[1;32m   1603\u001b[0m     impute_data\u001b[39m=\u001b[39;49mnew_data,\n\u001b[1;32m   1604\u001b[0m     datasets\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(datasets),\n\u001b[1;32m   1605\u001b[0m     variable_schema\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvariable_schema\u001b[39m.\u001b[39;49mcopy(),\n\u001b[1;32m   1606\u001b[0m     imputation_order\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvariable_training_order\u001b[39m.\u001b[39;49mcopy(),\n\u001b[1;32m   1607\u001b[0m     train_nonmissing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1608\u001b[0m     categorical_feature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_feature,\n\u001b[1;32m   1609\u001b[0m     save_all_iterations\u001b[39m=\u001b[39;49msave_all_iterations,\n\u001b[1;32m   1610\u001b[0m     copy_data\u001b[39m=\u001b[39;49mcopy_data,\n\u001b[1;32m   1611\u001b[0m )\n\u001b[1;32m   1613\u001b[0m \u001b[39m### Manage Randomness.\u001b[39;00m\n\u001b[1;32m   1614\u001b[0m \u001b[39mif\u001b[39;00m random_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.miniconda3/envs/default_prediction/lib/python3.10/site-packages/miceforest/ImputedData.py:102\u001b[0m, in \u001b[0;36mImputedData.__init__\u001b[0;34m(self, impute_data, datasets, variable_schema, imputation_order, train_nonmissing, categorical_feature, save_all_iterations, copy_data)\u001b[0m\n\u001b[1;32m     98\u001b[0m vars_with_any_missing \u001b[39m=\u001b[39m [\n\u001b[1;32m     99\u001b[0m     col \u001b[39mfor\u001b[39;00m col, ind \u001b[39min\u001b[39;00m na_where\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ind \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m    100\u001b[0m ]\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(vars_with_any_missing) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo missing values to impute.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[39m# Keep track of datatypes. Needed for loading kernels.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworking_dtypes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworking_data\u001b[39m.\u001b[39mdtypes\n",
      "\u001b[0;31mValueError\u001b[0m: No missing values to impute."
     ]
    }
   ],
   "source": [
    "kernel.transform(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"mths_since_last_major_derog\"] = pd.qcut(\n",
    "    X[\"mths_since_last_major_derog\"],\n",
    "    [0, 0.25, 0.5, 0.75, 1],\n",
    "    labels=[\"1_quant\", \"2_quant\", \"3_quant\", \"4_quant\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [\n",
    "    X[\"mths_since_last_major_derog\"].quantile(q) for q in [0, 0.25, 0.5, 0.75, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 26.0, 43.0, 60.0, 159.0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         missing\n",
       "1         missing\n",
       "2         missing\n",
       "3         missing\n",
       "4         missing\n",
       "           ...   \n",
       "177074    missing\n",
       "177075    missing\n",
       "177076    missing\n",
       "177077    missing\n",
       "177078    missing\n",
       "Name: mths_since_last_major_derog, Length: 177079, dtype: category\n",
       "Categories (5, object): ['1_quant' < '2_quant' < '3_quant' < '4_quant' < 'missing']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.cut(\n",
    "    X[\"mths_since_last_major_derog\"],\n",
    "    quantiles,\n",
    "    labels=[\"1_quant\", \"2_quant\", \"3_quant\", \"4_quant\"],\n",
    ")\n",
    "t = t.cat.add_categories([\"missing\"])\n",
    "t.fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(\"resources/data/splitted/X_train.parquet\")\n",
    "X_valid = pd.read_parquet(\"resources/data/splitted/X_valid.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dec-2008',\n",
       " 'Feb-2008',\n",
       " 'Jan-2008',\n",
       " 'Jun-2008',\n",
       " 'Mar-2008',\n",
       " 'May-2007',\n",
       " 'May-2008',\n",
       " 'Oct-2007',\n",
       " 'Oct-2008',\n",
       " 'Sep-2007',\n",
       " 'Sep-2008'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X_train[\"last_credit_pull_d\"].drop_duplicates().values) - set(\n",
    "    X_valid[\"last_credit_pull_d\"].drop_duplicates().values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jul-2007', 'Jul-2008'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X_valid[\"last_credit_pull_d\"].drop_duplicates().values) - set(\n",
    "    X_train[\"last_credit_pull_d\"].drop_duplicates().values\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('default_prediction')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e1f6d670a398f79a37d96720a30f8a8a62dff7decaa5b825d061b7e0997c08b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
